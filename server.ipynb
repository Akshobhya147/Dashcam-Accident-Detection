{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "61EBjdcOZhF5",
    "outputId": "1415649a-1581-4cf1-cf68-f89a8bc57de5"
   },
   "outputs": [],
   "source": [
    "!pip install remotezip tqdm opencv-python einops\n",
    "# !pip install -U tensorflow keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "91S2vNlbZXHG"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import einops\n",
    "import numpy as np\n",
    "import remotezip as rz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-DCjYjz2LLKl"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GZcB_7dg-EZJ"
   },
   "outputs": [],
   "source": [
    "# Define the dimensions of one frame in the set of frames created\n",
    "HEIGHT = 224\n",
    "WIDTH = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yD_sDIBlNu7K"
   },
   "outputs": [],
   "source": [
    "class Conv2Plus1D(keras.layers.Layer):\n",
    "  def __init__(self, filters, kernel_size, padding):\n",
    "    \"\"\"\n",
    "      A sequence of convolutional layers that first apply the convolution operation over the\n",
    "      spatial dimensions, and then the temporal dimension.\n",
    "    \"\"\"\n",
    "    super().__init__()\n",
    "    self.seq = keras.Sequential([\n",
    "        # Spatial decomposition\n",
    "        layers.Conv3D(filters=filters,\n",
    "                      kernel_size=(1, kernel_size[1], kernel_size[2]),\n",
    "                      padding=padding),\n",
    "        # Temporal decomposition\n",
    "        layers.Conv3D(filters=filters,\n",
    "                      kernel_size=(kernel_size[0], 1, 1),\n",
    "                      padding=padding)\n",
    "        ])\n",
    "\n",
    "  def call(self, x):\n",
    "    return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tjxAKHwn6mTJ"
   },
   "outputs": [],
   "source": [
    "class ResidualMain(keras.layers.Layer):\n",
    "  \"\"\"\n",
    "    Residual block of the model with convolution, layer normalization, and the\n",
    "    activation function, ReLU.\n",
    "  \"\"\"\n",
    "  def __init__(self, filters, kernel_size):\n",
    "    super().__init__()\n",
    "    self.seq = keras.Sequential([\n",
    "        Conv2Plus1D(filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same'),\n",
    "        layers.LayerNormalization(),\n",
    "        layers.ReLU(),\n",
    "        Conv2Plus1D(filters=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding='same'),\n",
    "        layers.LayerNormalization()\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znrk5BrL6kuq"
   },
   "outputs": [],
   "source": [
    "class Project(keras.layers.Layer):\n",
    "  \"\"\"\n",
    "    Project certain dimensions of the tensor as the data is passed through different\n",
    "    sized filters and downsampled.\n",
    "  \"\"\"\n",
    "  def __init__(self, units):\n",
    "    super().__init__()\n",
    "    self.seq = keras.Sequential([\n",
    "        layers.Dense(units),\n",
    "        layers.LayerNormalization()\n",
    "    ])\n",
    "\n",
    "  def call(self, x):\n",
    "    return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urjVgqvw-TlB"
   },
   "outputs": [],
   "source": [
    "def add_residual_block(input, filters, kernel_size):\n",
    "  \"\"\"\n",
    "    Add residual blocks to the model. If the last dimensions of the input data\n",
    "    and filter size does not match, project it such that last dimension matches.\n",
    "  \"\"\"\n",
    "  out = ResidualMain(filters,\n",
    "                     kernel_size)(input)\n",
    "\n",
    "  res = input\n",
    "  # Using the Keras functional APIs, project the last dimension of the tensor to\n",
    "  # match the new filter size\n",
    "  if out.shape[-1] != input.shape[-1]:\n",
    "    res = Project(out.shape[-1])(res)\n",
    "\n",
    "  return layers.add([res, out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQOWuc2I-QqK"
   },
   "outputs": [],
   "source": [
    "class ResizeVideo(keras.layers.Layer):\n",
    "  def __init__(self, height, width):\n",
    "    super().__init__()\n",
    "    self.height = height\n",
    "    self.width = width\n",
    "    self.resizing_layer = layers.Resizing(self.height, self.width)\n",
    "\n",
    "  def call(self, video):\n",
    "    \"\"\"\n",
    "      Use the einops library to resize the tensor.\n",
    "\n",
    "      Args:\n",
    "        video: Tensor representation of the video, in the form of a set of frames.\n",
    "\n",
    "      Return:\n",
    "        A downsampled size of the video according to the new height and width it should be resized to.\n",
    "    \"\"\"\n",
    "    # b stands for batch size, t stands for time, h stands for height,\n",
    "    # w stands for width, and c stands for the number of channels.\n",
    "    old_shape = einops.parse_shape(video, 'b t h w c')\n",
    "    images = einops.rearrange(video, 'b t h w c -> (b t) h w c')\n",
    "    images = self.resizing_layer(images)\n",
    "    videos = einops.rearrange(\n",
    "        images, '(b t) h w c -> b t h w c',\n",
    "        t = old_shape['t'])\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfitXthAxMXC"
   },
   "outputs": [],
   "source": [
    "dashing=tf.keras.models.load_model('dashing_model.keras',custom_objects={'Conv2Plus1D':Conv2Plus1D,'ResizeVideo':ResizeVideo,'Project':Project,'ResidualMain':ResidualMain,'add_residual_block':add_residual_block})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c2JGhRIuxMXC",
    "outputId": "2817df34-a11c-425b-dc19-38adb4c8b89a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 50, 224, 224, 3)]    0         []                            \n",
      "                                                                                                  \n",
      " conv2_plus1d (Conv2Plus1D)  (None, 50, 224, 224, 16)     3152      ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 50, 224, 224, 16)     64        ['conv2_plus1d[0][0]']        \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (None, 50, 224, 224, 16)     0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " resize_video (ResizeVideo)  (None, 50, 112, 112, 16)     0         ['re_lu[0][0]']               \n",
      "                                                                                                  \n",
      " residual_main (ResidualMai  (None, 50, 112, 112, 16)     6272      ['resize_video[0][0]']        \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 50, 112, 112, 16)     0         ['resize_video[0][0]',        \n",
      "                                                                     'residual_main[0][0]']       \n",
      "                                                                                                  \n",
      " resize_video_1 (ResizeVide  (None, 50, 56, 56, 16)       0         ['add[0][0]']                 \n",
      " o)                                                                                               \n",
      "                                                                                                  \n",
      " project (Project)           (None, 50, 56, 56, 32)       608       ['resize_video_1[0][0]']      \n",
      "                                                                                                  \n",
      " residual_main_1 (ResidualM  (None, 50, 56, 56, 32)       20224     ['resize_video_1[0][0]']      \n",
      " ain)                                                                                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 50, 56, 56, 32)       0         ['project[0][0]',             \n",
      "                                                                     'residual_main_1[0][0]']     \n",
      "                                                                                                  \n",
      " resize_video_2 (ResizeVide  (None, 50, 28, 28, 32)       0         ['add_1[0][0]']               \n",
      " o)                                                                                               \n",
      "                                                                                                  \n",
      " project_1 (Project)         (None, 50, 28, 28, 64)       2240      ['resize_video_2[0][0]']      \n",
      "                                                                                                  \n",
      " residual_main_2 (ResidualM  (None, 50, 28, 28, 64)       80384     ['resize_video_2[0][0]']      \n",
      " ain)                                                                                             \n",
      "                                                                                                  \n",
      " add_2 (Add)                 (None, 50, 28, 28, 64)       0         ['project_1[0][0]',           \n",
      "                                                                     'residual_main_2[0][0]']     \n",
      "                                                                                                  \n",
      " resize_video_3 (ResizeVide  (None, 50, 14, 14, 64)       0         ['add_2[0][0]']               \n",
      " o)                                                                                               \n",
      "                                                                                                  \n",
      " project_2 (Project)         (None, 50, 14, 14, 128)      8576      ['resize_video_3[0][0]']      \n",
      "                                                                                                  \n",
      " residual_main_3 (ResidualM  (None, 50, 14, 14, 128)      320512    ['resize_video_3[0][0]']      \n",
      " ain)                                                                                             \n",
      "                                                                                                  \n",
      " add_3 (Add)                 (None, 50, 14, 14, 128)      0         ['project_2[0][0]',           \n",
      "                                                                     'residual_main_3[0][0]']     \n",
      "                                                                                                  \n",
      " global_average_pooling3d (  (None, 128)                  0         ['add_3[0][0]']               \n",
      " GlobalAveragePooling3D)                                                                          \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 128)                  0         ['global_average_pooling3d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 1)                    129       ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 442161 (1.69 MB)\n",
      "Trainable params: 442129 (1.69 MB)\n",
      "Non-trainable params: 32 (128.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dashing.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xCpKy0T8jMd2"
   },
   "outputs": [],
   "source": [
    "y=np.array([[1,2],[3,4]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yGdGTcKGjQ23",
    "outputId": "1bdf9dff-ae35-47f0-d2de-5fbbb4f3d6b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.flatten()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03sFr9VCPz2d",
    "outputId": "ad0b5c06-9328-483c-bfa4-ebd81db49b04"
   },
   "outputs": [],
   "source": [
    "!pip install fastapi\n",
    "!pip install uvicorn\n",
    "!pip install pickle5\n",
    "!pip install pydantic\n",
    "!pip install scikit-learn\n",
    "!pip install requests\n",
    "!pip install pypi-json\n",
    "!pip install pyngrok\n",
    "!pip install nest-asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n-ize4pqR4Y1"
   },
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import pickle\n",
    "import json\n",
    "import uvicorn\n",
    "from pyngrok import ngrok\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gw9a-r-RGS1n"
   },
   "outputs": [],
   "source": [
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fH-2Snr9HDRd"
   },
   "outputs": [],
   "source": [
    "origins = [\"*\"]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liEQfnzsSdu8"
   },
   "outputs": [],
   "source": [
    "@app.get(\"/\")\n",
    "def read_root():\n",
    "  return {\"Hello\": \"World\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VwlRXkePyZVG",
    "outputId": "8350dcb4-fa15-4b03-9300-757b082dfc78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 27s 27s/step\n"
     ]
    }
   ],
   "source": [
    "def generator():\n",
    "  for frames, label in data:\n",
    "    yield frames, label\n",
    "\n",
    "    # Define the output signature\n",
    "output_signature = (tf.TensorSpec(shape=(50, 224, 224, 3), dtype=tf.float32),tf.TensorSpec(shape=(), dtype=tf.int16))\n",
    "\n",
    "batch_size=8\n",
    "dataset = tf.data.Dataset.from_generator(generator,output_signature=output_signature).shuffle(buffer_size=100)\n",
    "test = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "y_pred=dashing.predict(test)\n",
    "y_pred=y_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2uJIMj4gGIr"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import json\n",
    "\n",
    "\n",
    "# Custom JSON encoder for NumPy arrays\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()  # Convert NumPy arrays to lists\n",
    "        return super().default(obj)\n",
    "\n",
    "# Pydantic model for the data structure\n",
    "class DataItem(BaseModel):\n",
    "    A: List[List[List[List[float]]]]  # Nested lists representing the 4D array\n",
    "    B: int  # Integer value\n",
    "\n",
    "@app.post(\"/process-data3/\")\n",
    "async def process_data3(indata: List[DataItem]):\n",
    "  # Convert JSON back to NumPy arrays\n",
    "  reconstructed_data = [\n",
    "      (np.array(item.A, dtype=np.float32), np.int64(item.B)) for item in indata\n",
    "  ]\n",
    "\n",
    "  def generator():\n",
    "    for frames, label in reconstructed_data:\n",
    "      yield frames, label\n",
    "\n",
    "  # Define the output signature\n",
    "  output_signature = (tf.TensorSpec(shape=(50, 224, 224, 3), dtype=tf.float32),tf.TensorSpec(shape=(), dtype=tf.int16))\n",
    "\n",
    "  batch_size=8\n",
    "  dataset = tf.data.Dataset.from_generator(generator,output_signature=output_signature).shuffle(buffer_size=100)\n",
    "  test = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "  y_pred=dashing.predict(test)\n",
    "  y_pred=y_pred.flatten()\n",
    "  _0s,_1s=0,0\n",
    "  for a in y_pred:\n",
    "    if(a<0.5):\n",
    "      _0s+=1\n",
    "    else:\n",
    "      _1s+=1\n",
    "  ground_truth=False\n",
    "  if(_1s>=_0s):\n",
    "    ground_truth=True\n",
    "\n",
    "  return {\n",
    "      \"message\": \"Data processed successfully!\",\n",
    "      \"_1s\":_1s,\n",
    "      \"_0s\":_0s,\n",
    "      \"ground_truth\":ground_truth\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "kVKae2bcUmXa",
    "outputId": "43470d46-f642-4eb2-f3b0-fca458a87303"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
       "      pre.function-repr-contents {\n",
       "        overflow-x: auto;\n",
       "        padding: 8px 12px;\n",
       "        max-height: 500px;\n",
       "      }\n",
       "\n",
       "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
       "        cursor: pointer;\n",
       "        max-height: 100px;\n",
       "      }\n",
       "    </style>\n",
       "    <pre style=\"white-space: initial; background:\n",
       "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
       "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.prefetch_op._PrefetchDataset</b><br/>def __init__(input_dataset, buffer_size, slack_period=None, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/prefetch_op.py</a>A `Dataset` that asynchronously prefetches its input.</pre>\n",
       "      <script>\n",
       "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
       "        for (const element of document.querySelectorAll('.filepath')) {\n",
       "          element.style.display = 'block'\n",
       "          element.onclick = (event) => {\n",
       "            event.preventDefault();\n",
       "            event.stopPropagation();\n",
       "            google.colab.files.view(element.textContent, 31);\n",
       "          };\n",
       "        }\n",
       "      }\n",
       "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
       "        element.onclick = (event) => {\n",
       "          event.preventDefault();\n",
       "          event.stopPropagation();\n",
       "          element.classList.toggle('function-repr-contents-collapsed');\n",
       "        };\n",
       "      }\n",
       "      </script>\n",
       "      </div>"
      ],
      "text/plain": [
       "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-KVh7Zd2ZkAU",
    "outputId": "7c855258-c9d5-481e-9e3d-a38963ffebc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!ngrok config add-authtoken \"Your Auth token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "743kV9G0SW-p",
    "outputId": "a031995e-1cc1-42b1-8b3f-5952bf54f1d9"
   },
   "outputs": [],
   "source": [
    "ngrok_tunnel = ngrok.connect(8000)\n",
    "print('Public URL:', ngrok_tunnel.public_url)\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=8000)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
